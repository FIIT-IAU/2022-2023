{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#    http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or\n",
    "# implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Pandas (continue)\n",
    "\n",
    "URL https://www.freecodecamp.org/news/how-to-combine-multiple-csv-files-with-8-lines-of-code-265183e0854/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(53940, 10)"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = sns.load_dataset('diamonds')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   carat      cut color clarity  depth  table  price     x     y     z\n0   0.23    Ideal     E     SI2   61.5   55.0    326  3.95  3.98  2.43\n1   0.21  Premium     E     SI1   59.8   61.0    326  3.89  3.84  2.31\n2   0.23     Good     E     VS1   56.9   65.0    327  4.05  4.07  2.31\n3   0.29  Premium     I     VS2   62.4   58.0    334  4.20  4.23  2.63\n4   0.31     Good     J     SI2   63.3   58.0    335  4.34  4.35  2.75",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>carat</th>\n      <th>cut</th>\n      <th>color</th>\n      <th>clarity</th>\n      <th>depth</th>\n      <th>table</th>\n      <th>price</th>\n      <th>x</th>\n      <th>y</th>\n      <th>z</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.23</td>\n      <td>Ideal</td>\n      <td>E</td>\n      <td>SI2</td>\n      <td>61.5</td>\n      <td>55.0</td>\n      <td>326</td>\n      <td>3.95</td>\n      <td>3.98</td>\n      <td>2.43</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.21</td>\n      <td>Premium</td>\n      <td>E</td>\n      <td>SI1</td>\n      <td>59.8</td>\n      <td>61.0</td>\n      <td>326</td>\n      <td>3.89</td>\n      <td>3.84</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.23</td>\n      <td>Good</td>\n      <td>E</td>\n      <td>VS1</td>\n      <td>56.9</td>\n      <td>65.0</td>\n      <td>327</td>\n      <td>4.05</td>\n      <td>4.07</td>\n      <td>2.31</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.29</td>\n      <td>Premium</td>\n      <td>I</td>\n      <td>VS2</td>\n      <td>62.4</td>\n      <td>58.0</td>\n      <td>334</td>\n      <td>4.20</td>\n      <td>4.23</td>\n      <td>2.63</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.31</td>\n      <td>Good</td>\n      <td>J</td>\n      <td>SI2</td>\n      <td>63.3</td>\n      <td>58.0</td>\n      <td>335</td>\n      <td>4.34</td>\n      <td>4.35</td>\n      <td>2.75</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 1. Spliting a DataFrame\n",
    "## 1.1 Splitting by row index\n",
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" width=\"60%\" height=\"60%\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(1000, 10)"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_1 = df.iloc[:1000,:]\n",
    "df_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(52939, 10)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_2 = df.iloc[1001:,:]\n",
    "df_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 1.2 Splitting dataframe in a particular size (60%, random selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(32364, 10)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_split = df.sample(frac=0.6, random_state=200)\n",
    "df_split.reset_index()\n",
    "df_split.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Splitting dataframe by groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "grouped = df.groupby(df.color)\n",
    "df_new = grouped.get_group(\"E\")\n",
    "df_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 2. Join DataFrames\n",
    "<img src=\"https://i.stack.imgur.com/h9Pln.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'key': ['K0', 'K1', 'K2', 'K3', 'K4', 'K5'],\n",
    "                   'A': ['A0', 'A1', 'A2', 'A3', 'A4', 'A5']})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "other = pd.DataFrame({'key': ['K0', 'K1', 'K2'],\n",
    "                      'B': ['B0', 'B1', 'B2']})\n",
    "other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.1 Left join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.join(other, how='left', lsuffix='_caller', rsuffix='_other')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.2 Right join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.join(other, how='right', lsuffix='_caller', rsuffix='_other')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.3 Inner join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.join(other, how='inner', lsuffix='_caller', rsuffix='_other')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 2.4 Outer join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df2 = df.join(other, how='outer', lsuffix='_caller', rsuffix='_other')\n",
    "df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 3. Working with more datasets\n",
    "**Concat more files in the same format, then save the combined file for later use**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/input\n"
     ]
    },
    {
     "data": {
      "text/plain": "['FR040120000800100hour.1-1-1999.31-12-2012',\n 'FR040370000800100hour.1-1-1999.31-12-2012',\n 'BETN0290000800100hour.1-1-1990.31-12-2012',\n 'BETR8010000800100hour.1-1-1990.31-12-2012']"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir_in = 'data/input'\n",
    "print(dir_in)\n",
    "os.listdir(dir_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Select files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/input/FR040120000800100hour.1-1-1999.31-12-2012\n",
      "data/input/FR040370000800100hour.1-1-1999.31-12-2012\n",
      "data/input/BETN0290000800100hour.1-1-1990.31-12-2012\n",
      "data/input/BETR8010000800100hour.1-1-1990.31-12-2012\n"
     ]
    }
   ],
   "source": [
    "# all files with .csv \n",
    "# extension = 'csv'\n",
    "# filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
    "\n",
    "# all files\n",
    "filenames = [i for i in glob.glob(dir_in + '/*')]\n",
    "print(*filenames, sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Concat selected files to one combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "combined_file = pd.concat([pd.read_csv(f) for f in filenames ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Export to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "dir_out = '.'\n",
    "filename_out = 'combined_file.csv'\n",
    "combined_file.to_csv(dir_out + '/' + filename_out, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 4. Linear column removing\n",
    "\n",
    "## 4.1 Identify and remove columns that contain a single value\n",
    "**The number of unique values for each column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     238\n",
      "1     297\n",
      "2     927\n",
      "3     933\n",
      "4     179\n",
      "5     375\n",
      "6     820\n",
      "7     618\n",
      "8     561\n",
      "9      57\n",
      "10    577\n",
      "11     59\n",
      "12     73\n",
      "13    107\n",
      "14     53\n",
      "15     91\n",
      "16    893\n",
      "17    810\n",
      "18    170\n",
      "19     53\n",
      "20     68\n",
      "21      9\n",
      "22      1\n",
      "23     92\n",
      "24      9\n",
      "25      8\n",
      "26      9\n",
      "27    308\n",
      "28    447\n",
      "29    392\n",
      "30    107\n",
      "31     42\n",
      "32      4\n",
      "33     45\n",
      "34    141\n",
      "35    110\n",
      "36      3\n",
      "37    758\n",
      "38      9\n",
      "39      9\n",
      "40    388\n",
      "41    220\n",
      "42    644\n",
      "43    649\n",
      "44    499\n",
      "45      2\n",
      "46    937\n",
      "47    169\n",
      "48    286\n",
      "49      2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('data/oil-spill.csv', header=None)\n",
    "print(df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Remove these columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(937, 50)\n",
      "[22]\n",
      "(937, 49)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('data/oil-spill.csv', header=None) \n",
    "print(df.shape)\n",
    "\n",
    "# get number of unique values for each column \n",
    "# record columns to delete\n",
    "counts = df.nunique()\n",
    "to_del = [i for i,v in enumerate(counts) if v == 1]\n",
    "print(to_del)\n",
    "\n",
    "# drop useless columns \n",
    "df.drop(to_del, axis=1, inplace=True) \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.2 Consider columns that have very few values\n",
    "**Percentage of unique values in each columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0, 238, 25.4%\n",
      "1, 297, 31.7%\n",
      "2, 927, 98.9%\n",
      "3, 933, 99.6%\n",
      "4, 179, 19.1%\n",
      "5, 375, 40.0%\n",
      "6, 820, 87.5%\n",
      "7, 618, 66.0%\n",
      "8, 561, 59.9%\n",
      "9, 57, 6.1%\n",
      "10, 577, 61.6%\n",
      "11, 59, 6.3%\n",
      "12, 73, 7.8%\n",
      "13, 107, 11.4%\n",
      "14, 53, 5.7%\n",
      "15, 91, 9.7%\n",
      "16, 893, 95.3%\n",
      "17, 810, 86.4%\n",
      "18, 170, 18.1%\n",
      "19, 53, 5.7%\n",
      "20, 68, 7.3%\n",
      "21, 9, 1.0%\n",
      "22, 1, 0.1%\n",
      "23, 92, 9.8%\n",
      "24, 9, 1.0%\n",
      "25, 8, 0.9%\n",
      "26, 9, 1.0%\n",
      "27, 308, 32.9%\n",
      "28, 447, 47.7%\n",
      "29, 392, 41.8%\n",
      "30, 107, 11.4%\n",
      "31, 42, 4.5%\n",
      "32, 4, 0.4%\n",
      "33, 45, 4.8%\n",
      "34, 141, 15.0%\n",
      "35, 110, 11.7%\n",
      "36, 3, 0.3%\n",
      "37, 758, 80.9%\n",
      "38, 9, 1.0%\n",
      "39, 9, 1.0%\n",
      "40, 388, 41.4%\n",
      "41, 220, 23.5%\n",
      "42, 644, 68.7%\n",
      "43, 649, 69.3%\n",
      "44, 499, 53.3%\n",
      "45, 2, 0.2%\n",
      "46, 937, 100.0%\n",
      "47, 169, 18.0%\n",
      "48, 286, 30.5%\n",
      "49, 2, 0.2%\n"
     ]
    }
   ],
   "source": [
    "from numpy import loadtxt\n",
    "from numpy import unique\n",
    "\n",
    "data = loadtxt('data/oil-spill.csv', delimiter=',')\n",
    "\n",
    "for i in range(data.shape[1]):\n",
    "    num = len(unique(data[:, i]))\n",
    "    percentage = float(num) / data.shape[0] * 100 \n",
    "    print('%d, %d, %.1f%%' % (i, num, percentage))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Remove these columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('data/oil-spill.csv', header=None)\n",
    "print(df.shape)\n",
    "\n",
    "counts = df.nunique()\n",
    "\n",
    "# record columns to delete if it contains less than 1% values\n",
    "to_del = [i for i,v in enumerate(counts) if (float(v)/df.shape[0]*100) < 1] \n",
    "print(to_del)\n",
    "\n",
    "# drop useless columns\n",
    "df.drop(to_del, axis=1, inplace=True)\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## 4.3 Identify and remove rows that contain duplicate data\n",
    "**Locate rows of duplicate data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "       0    1    2    3               4\n",
      "34   4.9  3.1  1.5  0.1     Iris-setosa\n",
      "37   4.9  3.1  1.5  0.1     Iris-setosa\n",
      "142  5.8  2.7  5.1  1.9  Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('data/iris.csv', header=None) \n",
    "dups = df.duplicated()\n",
    "\n",
    "# report if there are any duplicates \n",
    "print(dups.any())\n",
    "\n",
    "# list all duplicate rows \n",
    "print(df[dups])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "**Delete Rows That Contain Duplicate Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "df = read_csv('data/iris.csv', header=None) \n",
    "print(df.shape)\n",
    "\n",
    "# delete duplicate rows \n",
    "df.drop_duplicates(inplace=True) \n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}